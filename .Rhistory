# Librerías básicas
import os
import numpy as np
import pandas as pd
# Librerías de visualización
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.graph_objects as go
# Librerías de procesamiento de imágenes
from PIL import Image
# Librerías de machine learning (scikit-learn)
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
# Librerías de deep learning (PyTorch)
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision
import torchvision.transforms as transforms
# Otras librerías
import kagglehub
# Para guardar gráficos de Plotly como PNG
import plotly.io as pio
# Configurar Plotly para usar kaleido
pio.kaleido.scope.default_format = "png"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Usando dispositivo: {device}")
# Definir las transformaciones para el conjunto de entrenamiento
transform_train = transforms.Compose([
transforms.Resize((240, 320)),
transforms.ToTensor(),
transforms.Normalize((0.5, 0.5, 0.5),
(0.5, 0.5, 0.5))
])
# Definir las transformaciones para el conjunto de prueba y validación
transform_test = transforms.Compose([
transforms.Resize((240, 320)),
transforms.ToTensor(),
transforms.Normalize((0.5, 0.5, 0.5),
(0.5, 0.5, 0.5))
])
class MangoLeafDataset(Dataset):
def __init__(self, dataframe, transform=None):
"""
Args:
dataframe (pd.DataFrame): DataFrame que contiene las rutas de las imágenes y sus etiquetas.
transform (callable, optional): Transformaciones a aplicar a las imágenes.
"""
self.filepaths = dataframe['filepaths'].values
self.labels = dataframe['labels'].values
self.transform = transform
self.classes = sorted(dataframe['labels'].unique())
self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}
self.labels_idx = [self.class_to_idx[label] for label in self.labels]
def __len__(self):
return len(self.filepaths)
def __getitem__(self, idx):
img_path = self.filepaths[idx]
image = Image.open(img_path).convert('RGB')
label = self.labels_idx[idx]
if self.transform:
image = self.transform(image)
return image, label
# Generar rutas de datos con etiquetas
path = kagglehub.dataset_download("aryashah2k/mango-leaf-disease-dataset")
filepaths = []
labels = []
folders = os.listdir(path)
for folder in folders:
folder_path = os.path.join(path, folder)
if os.path.isdir(folder_path):
filelist = os.listdir(folder_path)
for file in filelist:
fpath = os.path.join(folder_path, file)
if fpath.endswith('.jpg') or fpath.endswith('.jpeg') or fpath.endswith('.png'):
filepaths.append(fpath)
labels.append(folder)
# Concatenar rutas de imagenes con etiquetas en un dataframe
Fseries = pd.Series(filepaths, name='filepaths')
Lseries = pd.Series(labels, name='labels')
df = pd.concat([Fseries, Lseries], axis=1)
# Verificar el DataFrame
print(df.head())
print(f'Tamaño del DataFrame: {df.shape}')
# Contar el número de imágenes por clase
class_counts = df['labels'].value_counts().reset_index()
class_counts.columns = ['Clase', 'Cantidad']
# Visualización interactiva con Plotly
fig = px.bar(class_counts, x='Clase', y='Cantidad', title='Distribución de Imágenes por Clase',
labels={'Cantidad': 'Número de Imágenes', 'Clase': 'Clase'},
text='Cantidad')
fig.update_traces(textposition='outside')
fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')
# Guardar el gráfico como PNG
fig.write_image("distribucion_imagenes.png")
# Mostrar el gráfico en HTML (opcional)
# fig.show()
# Primero, dividir en entrenamiento (70%) y prueba+validación (30%)
train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['labels'], random_state=42)
# Luego, dividir el conjunto temporal en validación (15%) y prueba (15%)
val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['labels'], random_state=42)
print(f'Tamaño del conjunto de entrenamiento: {train_df.shape}')
print(f'Tamaño del conjunto de validación: {val_df.shape}')
print(f'Tamaño del conjunto de prueba: {test_df.shape}')
# Función para crear la gráfica de distribución
def plot_class_distribution(dataframe, title, filename):
class_counts = dataframe['labels'].value_counts().reset_index()
class_counts.columns = ['Clase', 'Cantidad']
fig = px.bar(class_counts, x='Clase', y='Cantidad', title=title,
labels={'Cantidad': 'Número de Imágenes', 'Clase': 'Clase'},
text='Cantidad')
fig.update_traces(textposition='outside')
fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')
# Guardar el gráfico como PNG
fig.write_image(filename)
# Opcionalmente, mostrar el gráfico
# fig.show()
# Visualizar y guardar
plot_class_distribution(train_df, 'Distribución de Clases en el Conjunto de Entrenamiento', 'distribucion_clases_train.png')
plot_class_distribution(val_df, 'Distribución de Clases en el Conjunto de Validación', 'distribucion_clases_val.png')
plot_class_distribution(test_df, 'Distribución de Clases en el Conjunto de Prueba', 'distribucion_clases_prueba.png')
# Crear instancias del dataset
train_dataset = MangoLeafDataset(train_df, transform=transform_train)
val_dataset = MangoLeafDataset(val_df, transform=transform_test)
test_dataset = MangoLeafDataset(test_df, transform=transform_test)
# Definir el tamaño del lote
batch_size = 64
# Crear DataLoaders
trainloader = DataLoader(
train_dataset,
batch_size=batch_size,
shuffle=True,
num_workers=0,
pin_memory=True if device.type == 'cuda' else False
)
valloader = DataLoader(
val_dataset,
batch_size=batch_size,
shuffle=False,
num_workers=0,
pin_memory=True if device.type == 'cuda' else False
)
testloader = DataLoader(
test_dataset,
batch_size=batch_size,
shuffle=False,
num_workers=0,
pin_memory=True if device.type == 'cuda' else False
)
class MangoCNN(nn.Module):
def __init__(self, num_classes=8):
super(MangoCNN, self).__init__()
self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # Entrada RGB
self.pool = nn.MaxPool2d(2, 2)
self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
self.fc1 = nn.Linear(64 * 60 * 80, 256)
self.fc2 = nn.Linear(256, num_classes)
def forward(self, x):
x = self.pool(F.relu(self.conv1(x)))  # [Batch, 32, 120, 160]
x = self.pool(F.relu(self.conv2(x)))  # [Batch, 64, 60, 80]
x = x.view(-1, 64 * 60 * 80)          # Aplanar
x = F.relu(self.fc1(x))
x = self.fc2(x)
return x
# Instanciar y mover el modelo al dispositivo
model = MangoCNN(num_classes=8).to(device)
print(model)
# Definir la Función de Pérdida y el Optimizador
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
num_epochs = 10
for epoch in range(num_epochs):
model.train()
running_loss = 0.0
correct = 0
total = 0
for i, (images, labels) in enumerate(trainloader):
# Mover los datos al dispositivo
images = images.to(device, non_blocking=True)
labels = labels.to(device, non_blocking=True)
# Reiniciar los gradientes
optimizer.zero_grad()
# Forward pass
outputs = model(images)
loss = criterion(outputs, labels)
# Backward pass y optimización
loss.backward()
optimizer.step()
# Acumular la pérdida
running_loss += loss.item()
# Calcular la precisión
_, predicted = torch.max(outputs.data, 1)
total += labels.size(0)
correct += (predicted == labels).sum().item()
# Mostrar estadísticas cada 100 lotes
if (i + 1) % 100 == 0:
print(f"Época [{epoch + 1}/{num_epochs}], Lote [{i + 1}/{len(trainloader)}], "
f"Pérdida: {running_loss / 100:.4f}, Precisión: {100 * correct / total:.2f}%")
running_loss = 0.0
# Evaluar en el conjunto de validación después de cada época
model.eval()
with torch.no_grad():
val_correct = 0
val_total = 0
for images, labels in valloader:
images = images.to(device, non_blocking=True)
labels = labels.to(device, non_blocking=True)
outputs = model(images)
_, predicted = torch.max(outputs.data, 1)
val_total += labels.size(0)
val_correct += (predicted == labels).sum().item()
val_accuracy = 100 * val_correct / val_total
print(f"Precisión en Validación después de la Época {epoch + 1}: {val_accuracy:.2f}%\n")
print("Entrenamiento del modelo CNN completado.")
model.eval()
with torch.no_grad():
test_correct = 0
test_total = 0
for images, labels in testloader:
images = images.to(device, non_blocking=True)
labels = labels.to(device, non_blocking=True)
outputs = model(images)
_, predicted = torch.max(outputs.data, 1)
test_total += labels.size(0)
test_correct += (predicted == labels).sum().item()
test_accuracy = 100 * test_correct / test_total
print(f"Precisión en el Conjunto de Prueba (CNN): {test_accuracy:.2f}%")
torch.save(model.state_dict(), 'mango_cnn.pth')
print("Modelo CNN guardado exitosamente.")
# Cargar el Modelo
loaded_model = MangoCNN(num_classes=8).to(device)
loaded_model.load_state_dict(torch.load('mango_cnn.pth'))
loaded_model.eval()
print("Modelo CNN cargado exitosamente.")
def flatten_images(data_loader):
"""
Toma un DataLoader y devuelve las imágenes aplanadas y sus etiquetas como arreglos de numpy.
Args:
data_loader (DataLoader): DataLoader que contiene las imágenes y etiquetas.
Returns:
X (np.ndarray): Arreglo de características aplanadas.
y (np.ndarray): Arreglo de etiquetas.
"""
X = []
y = []
for images, labels in data_loader:
images = images.view(images.size(0), -1)  # Aplanar imágenes
X.append(images.cpu().numpy())
y.append(labels.cpu().numpy())
X = np.vstack(X)
y = np.hstack(y)
return X, y
# Extraer características de entrenamiento y prueba
X_train, y_train = flatten_images(trainloader)
X_test, y_test = flatten_images(testloader)
print(f"Forma de X_train: {X_train.shape}")
print(f"Forma de y_train: {y_train.shape}")
print(f"Forma de X_test: {X_test.shape}")
print(f"Forma de y_test: {y_test.shape}")
# Entrenamiento de modelos base
svm_model = SVC(kernel='linear', random_state=42)
rf_model = RandomForestClassifier(random_state=42)
log_reg_model = LogisticRegression(max_iter=1000, random_state=42)
svm_model.fit(X_train, y_train)
rf_model.fit(X_train, y_train)
log_reg_model.fit(X_train, y_train)
print("Modelos base entrenados exitosamente.")
# Modelo híbrido con Stacking
stacking_model = StackingClassifier(
estimators=[('svm', svm_model), ('rf', rf_model), ('logreg', log_reg_model)],
final_estimator=LogisticRegression()  # Meta-modelo
)
stacking_model.fit(X_train, y_train)
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
