{
  "hash": "4478f281c0fbf50f6715a8e9b00d10dd",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"CPP3_Apaza_Cabezas_Ponce_Ruiz\"\njupyter: python3\nvariables:\n  idl: \"IDL3\"\n  curso: \"Machine Learning II\"\n  estudiantes: \n    - \"APAZA PEREZ OSCAR GONZALO\"\n    - \"CABEZAS HUANIO RUBEN KELVIN\"\n    - \"RUIZ ALVA JERSON ENMANUEL\"\n    - \"PONCE DE LEON TORRES FABYOLA KORAYMA\"\n  profesores:\n    - \"LUIS ANTONY LOPEZ QUIROZ\"\nformat:\n  pdf:\n    toc: true\n    toc-depth: 3\n    documentclass: article\n    papersize: \"a4\"\n    number-sections: true\n    number-depth: 4  \n    lang: es-PE\n    template-partials:\n      - before-body.tex\n    include-in-header: \n      text: |\n        \\usepackage{graphicx}\n        \\usepackage{float}\n        \\usepackage{geometry}\n        \\usepackage{titlesec}\n        \\usepackage{tabularx}\n        \\usepackage{booktabs}\n        \\usepackage{fancyhdr}\n        \\usepackage{appendix}\n        \\usepackage{caption}\n        \\usepackage[scaled]{helvet}\n        \\usepackage[T1]{fontenc}\n        \\renewcommand{\\familydefault}{\\sfdefault}\n        \n        % Configuración de la geometría\n        \\geometry{\n          a4paper,\n          left=3cm,\n          right=3cm,\n          top=2cm,\n          bottom=2.7cm,\n          headheight=2cm,\n          headsep=0.2cm\n        }\n        \n        % Configuración encabezado y pie\n        \\pagestyle{fancy}\n        \\fancyhf{}\n        \\renewcommand{\\footrulewidth}{0pt}\n        \\fancyfoot[R]{\\footnotesize{icontinental.edu.pe}}\n        \n        % Encabezado con imagen\n        \\fancyhead[C]{%\n          \\makebox[\\textwidth][c]{%\n            \\includegraphics[width=\\paperwidth]{encabezado.png}%\n          }%\n        }\n        \n        \\renewcommand{\\headrulewidth}{0pt}\n        \n        % Formato secciones\n        \\titleformat{\\section}\n          {\\normalfont\\Large\\bfseries}{\\thesection}{1em}{}\n          \n        % Contador figuras\n        \\newcounter{grafico}\n        \n        % Comando figuras\n        \\newcommand{\\figuragraficos}[2]{\n          \\stepcounter{grafico}\n          \\begin{figure}[H]\n            \\centering\n            \\includegraphics[width=0.8\\textwidth]{#1}\n            \\caption{#2}\n          \\end{figure}\n        }\n---\n\n\n\\newpage\n\n# Introducción\n\n## Instalación y Configuración de H2O\n\nEn este proyecto utilizaremos la librería de Machine Learning H2O, configurándola para aprovechar el poder de procesamiento de la GPU. H2O puede acelerar significativamente el entrenamiento de modelos cuando se configura correctamente con GPU. H2O requiere Java 8+ y la configuración adecuada para utilizar la GPU.\n\n## Importación de las Librerías Necesarias\n\nImportamos todas las librerías necesarias para el proyecto, incluyendo H2O y PyTorch.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Librerías básicas\nimport os\nimport numpy as np\nimport pandas as pd\n\n# Librerías de visualización\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Librerías de procesamiento de imágenes\nfrom PIL import Image\n\n# Librerías de machine learning (scikit-learn)\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\n# Librerías de deep learning (PyTorch)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\n\n# Otras librerías\nimport kagglehub\n\n# Librerías de H2O\nimport h2o\nfrom h2o.estimators import H2ORandomForestEstimator\nfrom h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\nfrom h2o.grid.grid_search import H2OGridSearch\n\n# Configuración de Matplotlib para mejorar el rendimiento\nplt.rcParams.update({'figure.max_open_warning': 0})\n```\n:::\n\n\n## Función para Guardar Gráficos con Matplotlib\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndef save_matplotlib_figure(fig, filename):\n    \"\"\"\n    Guarda una figura de Matplotlib en formato PNG.\n    \n    Args:\n        fig (matplotlib.figure.Figure): La figura de Matplotlib a guardar.\n        filename (str): El nombre del archivo donde se guardará la figura.\n    \"\"\"\n    if not os.path.exists(filename):\n        fig.savefig(filename, bbox_inches='tight')\n        plt.close(fig)\n        print(f\"Gráfico guardado como {filename}.\")\n    else:\n        print(f\"Archivo {filename} ya existe. Se omite el guardado para acelerar la ejecución.\")\n```\n:::\n\n\n## Definición y Entrenamiento del Modelo CNN con PyTorch\n\nDefinimos y entrenamos una red neuronal convolucional (CNN) utilizando PyTorch para la clasificación de imágenes.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Definir el dispositivo\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Usando dispositivo: {device}\")\n\n# Verificar qué GPU se está utilizando\nif device.type == 'cuda':\n    print(f\"Nombre de la GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memoria total de la GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9} GB\")\n    torch.cuda.set_device(0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUsando dispositivo: cuda\nNombre de la GPU: NVIDIA GeForce RTX 4060 Laptop GPU\nMemoria total de la GPU: 8.585216 GB\n```\n:::\n:::\n\n\n### **Optimización de Uso de la GPU**\n\nAseguramos que solo se utilice la GPU y optimizamos la memoria:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Limpiar la caché de la GPU para liberar memoria\nif device.type == 'cuda':\n    torch.cuda.empty_cache()\n    print(\"Caché de la GPU limpiada.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCaché de la GPU limpiada.\n```\n:::\n:::\n\n\n### **Definir las Transformaciones para el Conjunto de Entrenamiento**\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Definir las Transformaciones para el Conjunto de Entrenamiento\ntransform_train = transforms.Compose([\n    transforms.Resize((240, 320)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5),\n                         (0.5, 0.5, 0.5))\n])\n\n# Definir las Transformaciones para el Conjunto de Prueba y Validación\ntransform_test = transforms.Compose([\n    transforms.Resize((240, 320)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5),\n                         (0.5, 0.5, 0.5))\n])\n\nprint(\"Transformaciones definidas para entrenamiento y prueba/validación.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTransformaciones definidas para entrenamiento y prueba/validación.\n```\n:::\n:::\n\n\n### **Crear una Clase Personalizada para el Dataset**\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Crear una Clase Personalizada para el Dataset\nclass MangoLeafDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        \"\"\"\n        Args:\n            dataframe (pd.DataFrame): DataFrame que contiene las rutas de las imágenes y sus etiquetas.\n            transform (callable, optional): Transformaciones a aplicar a las imágenes.\n        \"\"\"\n        self.filepaths = dataframe['filepaths'].values\n        self.labels = dataframe['labels'].values\n        self.transform = transform\n        self.classes = sorted(dataframe['labels'].unique())\n        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n        self.labels_idx = [self.class_to_idx[label] for label in self.labels]\n\n    def __len__(self):\n        return len(self.filepaths)\n\n    def __getitem__(self, idx):\n        img_path = self.filepaths[idx]\n        image = Image.open(img_path).convert('RGB')  \n        label = self.labels_idx[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\nprint(\"Clase personalizada para el dataset creada exitosamente.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nClase personalizada para el dataset creada exitosamente.\n```\n:::\n:::\n\n\n# Carga y Preparación de los Datos\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Generar rutas de datos con etiquetas\npath = kagglehub.dataset_download(\"aryashah2k/mango-leaf-disease-dataset\")\nfilepaths = []\nlabels = []\n\nfolds = os.listdir(path)\nfor fold in folds:\n    foldpath = os.path.join(path, fold)\n    filelist = os.listdir(foldpath)\n    for file in filelist:\n        fpath = os.path.join(foldpath, file)\n        filepaths.append(fpath)\n        labels.append(fold)\n\n# Concatenar rutas de imagenes con etiquetas en un dataframe\nFseries = pd.Series(filepaths, name='filepaths')\nLseries = pd.Series(labels, name='labels')\ndf = pd.concat([Fseries, Lseries], axis=1)\n\n# Verificar el DataFrame\nprint(df.head())\nprint(f'Tamaño del DataFrame: {df.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n                                           filepaths       labels\n0  C:\\Users\\Jerson\\.cache\\kagglehub\\datasets\\arya...  Anthracnose\n1  C:\\Users\\Jerson\\.cache\\kagglehub\\datasets\\arya...  Anthracnose\n2  C:\\Users\\Jerson\\.cache\\kagglehub\\datasets\\arya...  Anthracnose\n3  C:\\Users\\Jerson\\.cache\\kagglehub\\datasets\\arya...  Anthracnose\n4  C:\\Users\\Jerson\\.cache\\kagglehub\\datasets\\arya...  Anthracnose\nTamaño del DataFrame: (4000, 2)\n```\n:::\n:::\n\n\n### **Dividir el Dataset en Entrenamiento, Validación y Prueba**\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Dividir el dataset en entrenamiento (70%), validación (15%) y prueba (15%)\ntrain_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['labels'], random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['labels'], random_state=42)\n\nprint(f'Tamaño del conjunto de entrenamiento: {train_df.shape}')\nprint(f'Tamaño del conjunto de validación: {val_df.shape}')\nprint(f'Tamaño del conjunto de prueba: {test_df.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTamaño del conjunto de entrenamiento: (2800, 2)\nTamaño del conjunto de validación: (600, 2)\nTamaño del conjunto de prueba: (600, 2)\n```\n:::\n:::\n\n\n### **Crear Instancias del Dataset y DataLoaders**\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# Crear instancias del dataset\ntrain_dataset = MangoLeafDataset(train_df, transform=transform_train)\nval_dataset = MangoLeafDataset(val_df, transform=transform_test)\ntest_dataset = MangoLeafDataset(test_df, transform=transform_test)\n\n# Definir el tamaño del lote\nbatch_size = 32\n\n# Crear DataLoaders\ntrainloader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=0,\n    pin_memory=True if device.type == 'cuda' else False\n)\nvalloader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=0,\n    pin_memory=True if device.type == 'cuda' else False\n)\ntestloader = DataLoader(\n    test_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=0,\n    pin_memory=True if device.type == 'cuda' else False\n)\n\nprint(\"DataLoaders para entrenamiento, validación y prueba creados exitosamente.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDataLoaders para entrenamiento, validación y prueba creados exitosamente.\n```\n:::\n:::\n\n\n# **Definir el Modelo CNN**\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nclass MangoCNN(nn.Module):\n    def __init__(self, num_classes=8):\n        super(MangoCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # Entrada RGB\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.fc1 = nn.Linear(64 * 60 * 80, 256)  \n        self.fc2 = nn.Linear(256, num_classes)\n    \n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))  # [Batch, 32, 120, 160]\n        x = self.pool(F.relu(self.conv2(x)))  # [Batch, 64, 60, 80]\n        x = x.view(-1, 64 * 60 * 80)          # Aplanar\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\nprint(\"Modelo CNN definido exitosamente.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModelo CNN definido exitosamente.\n```\n:::\n:::\n\n\n### **Instanciar y Mover el Modelo al Dispositivo**\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nmodel = MangoCNN(num_classes=8).to(device)\nprint(\"Modelo CNN instanciado y movido al dispositivo:\")\nprint(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModelo CNN instanciado y movido al dispositivo:\nMangoCNN(\n  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (fc1): Linear(in_features=307200, out_features=256, bias=True)\n  (fc2): Linear(in_features=256, out_features=8, bias=True)\n)\n```\n:::\n:::\n\n\n### **Definir la Función de Pérdida y el Optimizador**\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nprint(\"Función de pérdida y optimizador definidos exitosamente.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFunción de pérdida y optimizador definidos exitosamente.\n```\n:::\n:::\n\n\n### **Entrenar el Modelo CNN**\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nnum_epochs = 10\nprint(\"Inicio del entrenamiento del modelo CNN.\")\n\nfor epoch in range(num_epochs):\n    print(f\"\\n--- Comenzando la Época {epoch + 1}/{num_epochs} ---\")\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for i, (images, labels) in enumerate(trainloader):\n        try:\n            # Mover los datos al dispositivo\n            images = images.to(device, non_blocking=True)\n            labels = labels.to(device, non_blocking=True)\n            \n            # Reiniciar los gradientes\n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            # Backward pass y optimización\n            loss.backward()\n            optimizer.step()\n            \n            # Acumular la pérdida\n            running_loss += loss.item()\n            \n            # Calcular la precisión\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            # Mostrar estadísticas cada 100 lotes\n            if (i + 1) % 100 == 0:\n                avg_loss = running_loss / 100\n                accuracy = 100 * correct / total\n                print(f\"Época [{epoch + 1}/{num_epochs}], Lote [{i + 1}/{len(trainloader)}], \"\n                      f\"Pérdida: {avg_loss:.4f}, Precisión: {accuracy:.2f}%\")\n                running_loss = 0.0\n                correct = 0\n                total = 0\n        except Exception as e:\n            print(f\"Ocurrió un error en el lote {i + 1}: {e}\")\n            continue\n                \n    # Evaluar en el conjunto de validación después de cada época\n    model.eval()\n    with torch.no_grad():\n        val_correct = 0\n        val_total = 0\n        for images, labels in valloader:\n            images = images.to(device, non_blocking=True)\n            labels = labels.to(device, non_blocking=True)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n        val_accuracy = 100 * val_correct / val_total\n        print(f\"Precisión en Validación después de la Época {epoch + 1}: {val_accuracy:.2f}%\")\n\nprint(\"\\nEntrenamiento completado.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nInicio del entrenamiento del modelo CNN.\n\n--- Comenzando la Época 1/10 ---\nPrecisión en Validación después de la Época 1: 52.33%\n\n--- Comenzando la Época 2/10 ---\nPrecisión en Validación después de la Época 2: 64.50%\n\n--- Comenzando la Época 3/10 ---\nPrecisión en Validación después de la Época 3: 63.00%\n\n--- Comenzando la Época 4/10 ---\nPrecisión en Validación después de la Época 4: 73.17%\n\n--- Comenzando la Época 5/10 ---\nPrecisión en Validación después de la Época 5: 70.83%\n\n--- Comenzando la Época 6/10 ---\nPrecisión en Validación después de la Época 6: 78.33%\n\n--- Comenzando la Época 7/10 ---\nPrecisión en Validación después de la Época 7: 86.50%\n\n--- Comenzando la Época 8/10 ---\nPrecisión en Validación después de la Época 8: 85.50%\n\n--- Comenzando la Época 9/10 ---\nPrecisión en Validación después de la Época 9: 82.17%\n\n--- Comenzando la Época 10/10 ---\nPrecisión en Validación después de la Época 10: 84.17%\n\nEntrenamiento completado.\n```\n:::\n:::\n\n\n### **Evaluación del Modelo CNN en el Conjunto de Prueba**\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nmodel.eval()\nwith torch.no_grad():\n    test_correct = 0\n    test_total = 0\n    for images, labels in testloader:\n        images = images.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        test_total += labels.size(0)\n        test_correct += (predicted == labels).sum().item()\n    test_accuracy = 100 * test_correct / test_total\n    print(f\"Precisión en el Conjunto de Prueba (CNN): {test_accuracy:.2f}%\")\n    \n    # Guardar la precisión en una variable para uso posterior\n    cnn_test_accuracy = test_accuracy\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPrecisión en el Conjunto de Prueba (CNN): 85.83%\n```\n:::\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# Guardar la precisión del modelo CNN en un archivo para su posterior uso\nwith open(\"precision_prueba_cnn.txt\", \"w\") as f:\n    f.write(f\"{cnn_test_accuracy:.2f}%\")\nprint(\"Precisión del conjunto de prueba del modelo CNN guardada en 'precision_prueba_cnn.txt'.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPrecisión del conjunto de prueba del modelo CNN guardada en 'precision_prueba_cnn.txt'.\n```\n:::\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n# Generar y guardar una representación gráfica de la precisión en el conjunto de prueba para el modelo CNN utilizando Matplotlib\nfig, ax = plt.subplots(figsize=(6,4))\nax.bar(['CNN'], [cnn_test_accuracy], color='skyblue')\nax.set_ylim(0, 100)\nax.set_ylabel('Precisión (%)')\nax.set_title('Precisión en el Conjunto de Prueba para el Modelo CNN')\nfor i, v in enumerate([cnn_test_accuracy]):\n    ax.text(i, v + 1, f\"{v:.2f}%\", ha='center')\nfigure_filename = \"precision_prueba_cnn.png\"\nsave_matplotlib_figure(fig, figure_filename)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nArchivo precision_prueba_cnn.png ya existe. Se omite el guardado para acelerar la ejecución.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](CPP3_Apaza_Cabezas_Ponce_Ruiz_files/figure-pdf/cell-17-output-2.pdf){fig-pos='H'}\n:::\n:::\n\n\n\\figuragraficos{precision_prueba_cnn.png}{Precisión en el Conjunto de Prueba para el Modelo CNN}\n\n## Guardar el Modelo CNN\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\ntorch.save(model.state_dict(), 'mango_cnn.pth')\nprint(\"Modelo CNN guardado exitosamente en 'mango_cnn.pth'.\")\n\n# Cargar el Modelo\nloaded_model = MangoCNN(num_classes=8).to(device)\nloaded_model.load_state_dict(torch.load('mango_cnn.pth'))\nloaded_model.eval()\nprint(\"Modelo CNN cargado exitosamente desde 'mango_cnn.pth'.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModelo CNN guardado exitosamente en 'mango_cnn.pth'.\nModelo CNN cargado exitosamente desde 'mango_cnn.pth'.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Jerson\\AppData\\Local\\Temp\\ipykernel_14760\\1371283294.py:6: FutureWarning:\n\nYou are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n\n```\n:::\n:::\n\n\n# Extracción de Características y Preparación para H2O\n\nAhora, extraemos las características del modelo CNN y preparamos los datos para H2O.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n# Función para Extraer Características usando el Modelo CNN\ndef extract_features(data_loader, model, device):\n    \"\"\"\n    Extrae características de las imágenes utilizando un modelo CNN preentrenado.\n    \n    Args:\n        data_loader (DataLoader): DataLoader que contiene las imágenes y etiquetas.\n        model (nn.Module): Modelo CNN preentrenado.\n        device (torch.device): Dispositivo para ejecutar el modelo.\n        \n    Returns:\n        X (np.ndarray): Arreglo de características extraídas.\n        y (np.ndarray): Arreglo de etiquetas.\n    \"\"\"\n    model.eval()\n    features = []\n    labels_list = []\n    with torch.no_grad():\n        for images, labels in data_loader:\n            images = images.to(device, non_blocking=True)\n            outputs = model(images)\n            features.append(outputs.cpu().numpy())\n            labels_list.append(labels.cpu().numpy())\n    X = np.vstack(features)\n    y = np.hstack(labels_list)\n    return X, y\n\n# Extraer las Características de Entrenamiento y Prueba\nprint(\"Extrayendo características del conjunto de entrenamiento...\")\nX_train, y_train = extract_features(trainloader, model, device)\nprint(\"Características del conjunto de entrenamiento extraídas.\")\n\nprint(\"Extrayendo características del conjunto de prueba...\")\nX_test, y_test = extract_features(testloader, model, device)\nprint(\"Características del conjunto de prueba extraídas.\")\n\nprint(f\"Forma de X_train: {X_train.shape}\")\nprint(f\"Forma de y_train: {y_train.shape}\")\nprint(f\"Forma de X_test: {X_test.shape}\")\nprint(f\"Forma de y_test: {y_test.shape}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nExtrayendo características del conjunto de entrenamiento...\nCaracterísticas del conjunto de entrenamiento extraídas.\nExtrayendo características del conjunto de prueba...\nCaracterísticas del conjunto de prueba extraídas.\nForma de X_train: (2800, 8)\nForma de y_train: (2800,)\nForma de X_test: (600, 8)\nForma de y_test: (600,)\n```\n:::\n:::\n\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n# Guardar las características extraídas en archivos para su posterior visualización\nnp.save(\"X_train.npy\", X_train)\nnp.save(\"y_train.npy\", y_train)\nnp.save(\"X_test.npy\", X_test)\nnp.save(\"y_test.npy\", y_test)\nprint(\"Características extraídas guardadas en archivos .npy.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCaracterísticas extraídas guardadas en archivos .npy.\n```\n:::\n:::\n\n\n## Configuración de H2O y Preparación de los Datos para H2O\n\nInicializamos H2O y convertimos los datos extraídos a H2O Frames, optimizando para reducir la complejidad y utilizar modelos que aprovechen la GPU.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n# Inicializar H2O con soporte para GPU\nh2o.init(max_mem_size_GB=8, nthreads=-1, enable_assertions=False)\nprint(\"H2O inicializado exitosamente.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nChecking whether there is an H2O instance running at http://localhost:54321..... not found.\nAttempting to start a local H2O server...\n  Java Version: openjdk version \"23.0.1\" 2024-10-15\r; OpenJDK Runtime Environment (build 23.0.1+13)\r; OpenJDK 64-Bit Server VM (build 23.0.1+13, mixed mode, sharing)\n  Starting server from C:\\Users\\Jerson\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n  Ice root: C:\\Users\\Jerson\\AppData\\Local\\Temp\\tmpl31ubeju\n  JVM stdout: C:\\Users\\Jerson\\AppData\\Local\\Temp\\tmpl31ubeju\\h2o_Jerson_started_from_python.out\n  JVM stderr: C:\\Users\\Jerson\\AppData\\Local\\Temp\\tmpl31ubeju\\h2o_Jerson_started_from_python.err\n  Server is running at http://127.0.0.1:54321\nConnecting to H2O server at http://127.0.0.1:54321 ... successful.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n\n#h2o-table-1.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-1 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-1 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-1 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-1 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-1 .h2o-table th,\n#h2o-table-1 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-1 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-1\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption></caption>\n    <thead></thead>\n    <tbody><tr><td>H2O_cluster_uptime:</td>\n<td>01 secs</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>America/Lima</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.46.0.6</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>1 month and 22 days</td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_Jerson_1hioo4</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>7.984 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>24</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>24</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://127.0.0.1:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>Python_version:</td>\n<td>3.12.6 final</td></tr></tbody>\n  </table>\n</div>\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nH2O inicializado exitosamente.\n```\n:::\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\n# Convertir los datos de entrenamiento a DataFrame de Pandas con nombres de columnas válidos\ntrain_df_h2o = pd.DataFrame(X_train, columns=[f\"feature_{i}\" for i in range(X_train.shape[1])])\ntrain_df_h2o['label'] = y_train\n\n# Convertir los datos de prueba a DataFrame de Pandas con nombres de columnas válidos\ntest_df_h2o = pd.DataFrame(X_test, columns=[f\"feature_{i}\" for i in range(X_test.shape[1])])\ntest_df_h2o['label'] = y_test\n\n# Convertir a H2O Frames\ntrain_h2o = h2o.H2OFrame(train_df_h2o)\ntest_h2o = h2o.H2OFrame(test_df_h2o)\n\n# Definir la columna de destino y las características\ny = 'label'\nX = train_h2o.columns\nX.remove(y)\n\n# Asegurarse de que la columna de etiquetas sea categórica\ntrain_h2o[y] = train_h2o[y].asfactor()\ntest_h2o[y] = test_h2o[y].asfactor()\n\nprint(\"Datos convertidos a H2O Frames y preparados para entrenamiento.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParse progress: |████████████████████████████████████████████████████████████████| (done) 100%\nParse progress: |████████████████████████████████████████████████████████████████| (done) 100%\nDatos convertidos a H2O Frames y preparados para entrenamiento.\n```\n:::\n:::\n\n\n## Definición y Entrenamiento de los Modelos Base con H2OGridSearch\n\nUtilizaremos un **Random Forest Estimator** optimizado para GPU como modelo base y simplificaremos la búsqueda de hiperparámetros para reducir la complejidad.\n\n### **Random Forest con Búsqueda Aleatoria**\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\n# Definir los hiperparámetros para Random Forest con un espacio reducido\nrf_params = {\n    'ntrees': [50, 100],             \n    'max_depth': [20, 30],         \n    'min_rows': [10, 20],            \n    'sample_rate': [0.8],           \n    'col_sample_rate_per_tree': [0.8]         \n}\n\n# Definir los criterios de búsqueda para Random Search en lugar de Grid Search\nsearch_criteria = {\n    'strategy': \"RandomDiscrete\",    \n    'max_models': 8,                 \n    'seed': 42\n}\n\n# Inicializar el modelo Random Forest sin establecer col_sample_rate_change_per_level y col_sample_rate_per_tree\nrf = H2ORandomForestEstimator(\n    seed=42,                        \n    nfolds=3,                        \n    keep_cross_validation_predictions=True\n)\n\n# Configurar la búsqueda en cuadrícula para Random Forest con búsqueda aleatoria\nrf_grid = H2OGridSearch(\n    model=rf,\n    hyper_params=rf_params,\n    search_criteria=search_criteria\n)\n\n# Entrenar el Grid Search en el conjunto de entrenamiento\nprint(\"Iniciando Búsqueda Aleatoria para Random Forest...\")\ntry:\n    rf_grid.train(x=X, y=y, training_frame=train_h2o, validation_frame=test_h2o)\n    print(\"Búsqueda Aleatoria para Random Forest completada.\")\nexcept h2o.exceptions.H2OResponseError as e:\n    print(\"Ocurrió un error al entrenar la Búsqueda Aleatoria para Random Forest:\")\n    print(e)\n\n# Verificar si la búsqueda en cuadrícula ha generado modelos\nif len(rf_grid.models) == 0:\n    print(\"No se han entrenado modelos en la búsqueda en cuadrícula. Revisa los hiperparámetros y los datos.\")\nelse:\n    print(f\"Se han entrenado {len(rf_grid.models)} modelos en la búsqueda en cuadrícula.\")\n\n# Guardar una representación gráfica de los resultados de Grid Search utilizando Matplotlib\ndef plot_rf_grid_search(rf_grid, filename):\n    \"\"\"\n    Genera y guarda una gráfica de los resultados de Grid Search para Random Forest.\n    \n    Args:\n        rf_grid (H2OGridSearch): Objeto de Grid Search de H2O.\n        filename (str): Nombre del archivo donde se guardará la gráfica.\n    \"\"\"\n    if len(rf_grid.models) == 0:\n        print(\"No hay modelos para graficar en la búsqueda en cuadrícula.\")\n        return\n    \n    # Obtener los logloss de cada modelo\n    logloss = [model.logloss() for model in rf_grid.models]\n    model_ids = [model.model_id for model in rf_grid.models]\n    \n    # Crear la gráfica\n    fig, ax = plt.subplots(figsize=(10,6))\n    ax.barh(model_ids, logloss, color='skyblue')\n    ax.set_xlabel('Logloss')\n    ax.set_title('Resultados de Búsqueda Aleatoria para Random Forest')\n    ax.invert_yaxis()  # Para que el mejor modelo esté arriba\n    for i, v in enumerate(logloss):\n        ax.text(v + 0.001, i, f\"{v:.4f}\", va='center')\n    \n    # Guardar la figura\n    save_matplotlib_figure(fig, filename)\n\n# Generar la gráfica de Grid Search\nplot_rf_grid_search(rf_grid, \"rf_grid_search_optimized.png\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIniciando Búsqueda Aleatoria para Random Forest...\ndrf Grid Build progress: |███████████████████████████████████████████████████████| (done) 100%\nBúsqueda Aleatoria para Random Forest completada.\nSe han entrenado 8 modelos en la búsqueda en cuadrícula.\nArchivo rf_grid_search_optimized.png ya existe. Se omite el guardado para acelerar la ejecución.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](CPP3_Apaza_Cabezas_Ponce_Ruiz_files/figure-pdf/cell-23-output-2.pdf){fig-pos='H'}\n:::\n:::\n\n\n\\figuragraficos{rf_grid_search_optimized.png}{Resultados de Búsqueda Aleatoria para Random Forest}\n\n## Selección del Mejor Modelo Base\n\nSeleccionamos el mejor modelo de Random Forest basado en las métricas disponibles para clasificación multiclase.\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\n# Verificar si hay modelos en la búsqueda en cuadrícula\nif len(rf_grid.models) == 0:\n    raise ValueError(\"No se pudieron entrenar modelos en la búsqueda en cuadrícula. Revisa los hiperparámetros y los datos.\")\n\n# Seleccionar el mejor modelo de Random Forest\npreferred_metrics = ['logloss', 'mean_per_class_error']\n\nbest_rf = None\nfor metric in preferred_metrics:\n    try:\n        best_rf = rf_grid.get_grid(sort_by=metric, decreasing=False).models[0]\n        print(f\"Mejor modelo Random Forest basado en {metric.replace('_', ' ').capitalize()}:\")\n        print(best_rf)\n        break\n    except KeyError:\n        print(f\"La métrica '{metric}' no está disponible. Intentando con la siguiente métrica...\")\n    except h2o.exceptions.H2OResponseError as e:\n        print(f\"Ocurrió un error al intentar ordenar por '{metric}':\")\n        print(e)\n\nif best_rf is None:\n    raise ValueError(\"No se pudo seleccionar un mejor modelo porque ninguna métrica preferida está disponible.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMejor modelo Random Forest basado en Logloss:\nModel Details\n=============\nH2ORandomForestEstimator : Distributed Random Forest\nModel Key: Grid_DRF_py_1_sid_afef_model_python_1735087387909_1_model_4\n\n\nModel Summary: \n    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n    100                800                         537586                 5            18           10.355        11            87            48.7475\n\nModelMetricsMultinomial: drf\n** Reported on train data. **\n\nMSE: 0.13813542776041837\nRMSE: 0.37166574735966507\nLogLoss: 0.46398902748800813\nMean Per-Class Error: 0.12785714285714284\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\n0    1    2    3    4    5    6    7    Error      Rate\n---  ---  ---  ---  ---  ---  ---  ---  ---------  -----------\n334  0    4    3    5    3    1    0    0.0457143  16 / 350\n1    311  0    3    26   2    0    7    0.111429   39 / 350\n3    0    346  1    0    0    0    0    0.0114286  4 / 350\n3    9    1    332  3    1    1    0    0.0514286  18 / 350\n8    13   1    1    282  24   12   9    0.194286   68 / 350\n7    4    0    0    35   286  5    13   0.182857   64 / 350\n0    1    0    1    24   6    282  36   0.194286   68 / 350\n0    13   0    0    16   23   29   269  0.231429   81 / 350\n356  351  352  341  391  345  330  334  0.127857   358 / 2,800\n\nTop-8 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.872143\n2    0.961429\n3    0.9875\n4    0.995357\n5    0.996786\n6    0.998929\n7    0.999643\n8    1\n\nModelMetricsMultinomial: drf\n** Reported on validation data. **\n\nMSE: 0.15882709200175577\nRMSE: 0.3985311681685082\nLogLoss: 0.48543050030918616\nMean Per-Class Error: 0.15333333333333332\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\n0    1    2    3    4    5    6    7    Error      Rate\n---  ---  ---  ---  ---  ---  ---  ---  ---------  --------\n71   0    0    0    2    2    0    0    0.0533333  4 / 75\n0    51   0    0    13   1    0    10   0.32       24 / 75\n2    0    73   0    0    0    0    0    0.0266667  2 / 75\n1    0    0    69   4    1    0    0    0.08       6 / 75\n3    0    0    1    55   6    8    2    0.266667   20 / 75\n2    0    0    0    3    61   1    8    0.186667   14 / 75\n0    0    0    0    1    0    70   4    0.0666667  5 / 75\n0    0    0    0    2    7    8    58   0.226667   17 / 75\n79   51   73   70   80   78   87   82   0.153333   92 / 600\n\nTop-8 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.846667\n2    0.953333\n3    0.986667\n4    0.998333\n5    0.998333\n6    1\n7    1\n8    1\n\nModelMetricsMultinomial: drf\n** Reported on cross-validation data. **\n\nMSE: 0.14727904691408336\nRMSE: 0.38376952316994034\nLogLoss: 0.47720435937234723\nMean Per-Class Error: 0.13357142857142856\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\n0    1    2    3    4    5    6    7    Error       Rate\n---  ---  ---  ---  ---  ---  ---  ---  ----------  -----------\n333  1    3    3    6    3    1    0    0.0485714   17 / 350\n3    310  0    4    25   2    0    6    0.114286    40 / 350\n2    0    347  1    0    0    0    0    0.00857143  3 / 350\n4    13   1    329  1    1    1    0    0.06        21 / 350\n10   16   0    2    280  19   12   11   0.2         70 / 350\n8    3    0    0    35   283  6    15   0.191429    67 / 350\n1    1    0    0    21   7    284  36   0.188571    66 / 350\n0    11   0    0    17   30   32   260  0.257143    90 / 350\n361  355  351  339  385  345  336  328  0.133571    374 / 2,800\n\nTop-8 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.866429\n2    0.958571\n3    0.986429\n4    0.996786\n5    0.998214\n6    0.999643\n7    0.999643\n8    1\n\nCross-Validation Metrics Summary: \n                         mean      sd          cv_1_valid    cv_2_valid    cv_3_valid\n-----------------------  --------  ----------  ------------  ------------  ------------\naccuracy                 0.86638   0.00813656  0.867444      0.857763      0.873932\naic                      nan       0           nan           nan           nan\nauc                      nan       0           nan           nan           nan\nerr                      0.13362   0.00813656  0.132556      0.142237      0.126068\nerr_count                124.667   6.50641     125           131           118\nloglikelihood            nan       0           nan           nan           nan\nlogloss                  0.477121  0.0205567   0.499721      0.472108      0.459535\nmax_per_class_error      0.257537  0.0179624   0.239316      0.275229      0.258064\nmean_per_class_accuracy  0.866642  0.00994578  0.869519      0.855575      0.874832\nmean_per_class_error     0.133358  0.00994578  0.130481      0.144425      0.125168\nmse                      0.147286  0.00273629  0.148513      0.149194      0.144151\npr_auc                   nan       0           nan           nan           nan\nr2                       0.971886  0.00171204  0.971895      0.970169      0.973593\nrmse                     0.383768  0.00357399  0.385374      0.386257      0.379672\n\nScoring History: \n     timestamp            duration    number_of_trees    training_rmse        training_logloss     training_classification_error    training_auc    training_pr_auc    validation_rmse      validation_logloss    validation_classification_error    validation_auc    validation_pr_auc\n---  -------------------  ----------  -----------------  -------------------  -------------------  -------------------------------  --------------  -----------------  -------------------  --------------------  ---------------------------------  ----------------  -------------------\n     2024-12-24 19:43:24  14.299 sec  0.0                nan                  nan                  nan                              nan             nan                nan                  nan                   nan                                nan               nan\n     2024-12-24 19:43:24  14.317 sec  1.0                0.4233915612509133   2.516271611422613    0.19895287958115182              nan             nan                0.4431468772419603   3.3182508078577517    0.22833333333333333                nan               nan\n     2024-12-24 19:43:24  14.321 sec  2.0                0.41184321335812374  2.2354353770771587   0.18395303326810175              nan             nan                0.4154655871113011   0.8851947691110242    0.18333333333333332                nan               nan\n     2024-12-24 19:43:24  14.326 sec  3.0                0.4059424265941406   2.140919318346323    0.18097281831187412              nan             nan                0.4043530564527284   0.6480177538423773    0.18666666666666668                nan               nan\n     2024-12-24 19:43:24  14.331 sec  4.0                0.4123526672043428   2.1797333869833784   0.18764705882352942              nan             nan                0.40371364086772765  0.5467284820664055    0.17833333333333334                nan               nan\n     2024-12-24 19:43:24  14.336 sec  5.0                0.4045274789274776   2.095861521022617    0.18021750388399793              nan             nan                0.3967755519202214   0.5317128586133925    0.16                               nan               nan\n     2024-12-24 19:43:24  14.342 sec  6.0                0.4033313004752326   1.9863772716135666   0.17472474868358065              nan             nan                0.40036688525235153  0.48547334905616196   0.165                              nan               nan\n     2024-12-24 19:43:24  14.348 sec  7.0                0.40202958063224703  1.908059910941819    0.17326732673267325              nan             nan                0.39587911027022393  0.4777034054075075    0.16166666666666665                nan               nan\n     2024-12-24 19:43:24  14.354 sec  8.0                0.4024600950168275   1.7852496402565863   0.1775021385799829               nan             nan                0.3961525604295275   0.4770946211456062    0.15666666666666668                nan               nan\n     2024-12-24 19:43:24  14.362 sec  9.0                0.40291729617917493  1.749281321851275    0.17591450883682697              nan             nan                0.39396241743095267  0.47245958145249406   0.15833333333333333                nan               nan\n---  ---                  ---         ---                ---                  ---                  ---                              ---             ---                ---                  ---                   ---                                ---               ---\n     2024-12-24 19:43:26  15.883 sec  91.0               0.3724659548177505   0.4664721459753501   0.12892857142857142              nan             nan                0.3984250521198654   0.4850931275438299    0.15166666666666667                nan               nan\n     2024-12-24 19:43:26  15.915 sec  92.0               0.372263207097051    0.46587019314589245  0.12892857142857142              nan             nan                0.3982917241914884   0.48493520483493985   0.15333333333333332                nan               nan\n     2024-12-24 19:43:26  15.949 sec  93.0               0.37209539776956985  0.4656800475934984   0.12892857142857142              nan             nan                0.398344923448301    0.48501143851717854   0.15333333333333332                nan               nan\n     2024-12-24 19:43:26  15.984 sec  94.0               0.3719850259538673   0.4655811753072118   0.12857142857142856              nan             nan                0.3983940083380152   0.4852314485603384    0.15333333333333332                nan               nan\n     2024-12-24 19:43:26  16.019 sec  95.0               0.3720726064458759   0.46544353929054766  0.13035714285714287              nan             nan                0.39864010669351563  0.4858264560806857    0.15333333333333332                nan               nan\n     2024-12-24 19:43:26  16.051 sec  96.0               0.3718658948808821   0.46506021767641603  0.13                             nan             nan                0.3985441629615899   0.4856062158523835    0.15666666666666668                nan               nan\n     2024-12-24 19:43:26  16.087 sec  97.0               0.3718596662053876   0.465153610986008    0.12821428571428573              nan             nan                0.3984508609093876   0.48544652267698674   0.155                              nan               nan\n     2024-12-24 19:43:26  16.123 sec  98.0               0.37174702081166694  0.46458047291416993  0.12714285714285714              nan             nan                0.39835424422657867  0.4850779686491421    0.155                              nan               nan\n     2024-12-24 19:43:26  16.157 sec  99.0               0.3717838657420148   0.4645558712914334   0.12785714285714286              nan             nan                0.3983882926324259   0.4850153458955946    0.15333333333333332                nan               nan\n     2024-12-24 19:43:26  16.192 sec  100.0              0.37166574735966507  0.46398902748800813  0.12785714285714286              nan             nan                0.3985311681685082   0.48543050030918616   0.15333333333333332                nan               nan\n[101 rows x 14 columns]\n\n\nVariable Importances: \nvariable    relative_importance    scaled_importance    percentage\n----------  ---------------------  -------------------  ------------\nfeature_1   24642.5                1                    0.155333\nfeature_3   22999.8                0.933336             0.144978\nfeature_7   21580.4                0.875738             0.136031\nfeature_5   20292.5                0.823476             0.127913\nfeature_2   20179.8                0.818901             0.127203\nfeature_0   19494.9                0.791106             0.122885\nfeature_6   18789                  0.762463             0.118436\nfeature_4   10664.1                0.432753             0.0672208\n```\n:::\n:::\n\n\n## Creación del Modelo Híbrido con Stacking en H2O\n\nUtilizamos el modelo base optimizado para crear un modelo de ensamble apilado (**Stacked Ensemble**), simplificando la complejidad al usar solo un modelo base.\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\n# Crear el Stacked Ensemble con el mejor modelo Random Forest\nensemble = H2OStackedEnsembleEstimator(\n    model_id=\"ensemble_model\",\n    base_models=[best_rf.model_id]\n)\n\n# Entrenar el Stacked Ensemble\nprint(\"Entrenando el modelo Stacked Ensemble...\")\nensemble.train(x=X, y=y, training_frame=train_h2o)\nprint(\"Modelo Híbrido (Stacked Ensemble) entrenado exitosamente.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEntrenando el modelo Stacked Ensemble...\nstackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\nModelo Híbrido (Stacked Ensemble) entrenado exitosamente.\n```\n:::\n:::\n\n\nGuardar una representación gráfica del entrenamiento del modelo híbrido utilizando Matplotlib\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\n# Crear una representación gráfica simple del entrenamiento del modelo híbrido\nfig, ax = plt.subplots(figsize=(6,4))\nax.text(0.5, 0.5, \"Modelo Híbrido (Stacked Ensemble) entrenado exitosamente.\", \n        ha='center', va='center', fontsize=12, color='green')\nax.axis('off')\nax.set_title('Entrenamiento del Modelo Híbrido (Stacked Ensemble)')\n\n# Guardar la figura\nsave_matplotlib_figure(fig, \"stacked_ensemble_entrenado_optimized.png\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nArchivo stacked_ensemble_entrenado_optimized.png ya existe. Se omite el guardado para acelerar la ejecución.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](CPP3_Apaza_Cabezas_Ponce_Ruiz_files/figure-pdf/cell-26-output-2.pdf){fig-pos='H'}\n:::\n:::\n\n\n\\figuragraficos{stacked_ensemble_entrenado_optimized.png}{Entrenamiento del Modelo Híbrido (Stacked Ensemble) Optimizado}\n\n## Evaluación del Modelo Híbrido\n\nEvaluamos el rendimiento del modelo en el conjunto de prueba y lo comparamos con el modelo CNN.\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\n## Evaluación del Modelo Híbrido\n\n# Evaluar en el conjunto de prueba\nperformance = ensemble.model_performance(test_h2o)\nprint(\"Evaluación del Modelo Híbrido (Stacked Ensemble):\")\nprint(performance)\n\n# ===========================================================\n# 1) OBTENER PRECISIÓN (ACCURACY) DESDE LA TABLA DE HIT RATIOS\n# ===========================================================\n# En multiclase, la Top-1 Accuracy (k=1) es la precisión clásica.\nhit_ratio_table = performance.hit_ratio_table()\nprint(\"Tabla de Hit Ratios (Top-k Accuracy):\")\nprint(hit_ratio_table)\n\n# La fila con k=1 está normalmente en hit_ratio_table.cell_values[1]\ntop1_accuracy = float(hit_ratio_table.cell_values[1][1])\nprint(f\"Top-1 Accuracy (equivalente a Precisión) del modelo híbrido (Stacking): {top1_accuracy * 100:.2f}%\")\n\n# ================================================\n# 2) OBTENER MATRIZ DE CONFUSIÓN Y CÁLCULO MANUAL\n# ================================================\nconf_matrix = performance.confusion_matrix()\nprint(\"Matriz de Confusión del modelo híbrido (Stacking):\")\nprint(conf_matrix)\n\n# Podemos calcular la precisión a partir de la matriz de confusión:\ncm_list = conf_matrix.cell_values\nn_classes = len(cm_list) - 1  # -1 para ignorar la fila 'Totals' (última fila)\nsum_diagonal = 0\nsum_total = 0\n\n# Las filas 1..n_classes-1 representan las clases reales.\n# Las columnas 1..n_classes representan los conteos de cada clase predicha.\nfor i in range(1, n_classes):\n    sum_diagonal += cm_list[i][i]  # Elemento en la diagonal\n    row_counts = cm_list[i][1:n_classes]  # Conteos de esa fila (omitiendo la columna 0 y 'Totals')\n    sum_total += sum(row_counts)\n\naccuracy_conf_matrix = sum_diagonal / sum_total\nprint(f\"Precisión (cálculo manual) del modelo híbrido (Stacking): {accuracy_conf_matrix * 100:.2f}%\")\n\n# =====================================\n# 3) GRAFICAR LA MATRIZ DE CONFUSIÓN\n# =====================================\ncm_df = conf_matrix.as_data_frame()\nprint(\"\\nDataFrame de la matriz de confusión:\\n\", cm_df)\n\nimport matplotlib.pyplot as plt\n\n# Descarta la última fila (\"Totals\") y las últimas dos columnas (\"Error\", \"Rate\")\nn_classes = cm_df.shape[0] - 1\nrow_labels = cm_df.index[:n_classes]                       # Filas sin 'Totals'\ncol_labels = cm_df.columns[:n_classes]                    # Columnas sin 'Error' ni 'Rate'\nheatmap_data = cm_df.iloc[:n_classes, :n_classes].copy()  # Parte numérica de la matriz\n\nfig, ax = plt.subplots(figsize=(8, 6))\ncax = ax.matshow(heatmap_data.values, cmap='Blues')\nfig.colorbar(cax)\n\n# Ejes y títulos\nax.set_xticks(range(n_classes))\nax.set_yticks(range(n_classes))\nax.set_xticklabels(col_labels, rotation=90)\nax.set_yticklabels(row_labels)\nax.set_xlabel('Predicción')\nax.set_ylabel('Verdadero')\nax.set_title('Matriz de Confusión del Modelo Híbrido (Stacking) con H2O')\n\n# Escribir los valores en cada celda\nfor i in range(n_classes):\n    for j in range(n_classes):\n        ax.text(j, i, heatmap_data.iloc[i, j], \n                ha='center', va='center', color='red')\n\n# Guardar la figura\nsave_matplotlib_figure(fig, \"matriz_confusion_stacking_h2o_optimized.png\")\n\n# =================================================================\n# 4) GRAFICAR PRECISIÓN USANDO LA TOP-1 ACCURACY (k=1) DEL HIT RATIO\n# =================================================================\nfig, ax = plt.subplots(figsize=(6, 4))\nax.bar(['Híbrido'], [top1_accuracy * 100], color='lightgreen')\nax.set_ylim(0, 100)\nax.set_ylabel('Precisión (%)')\nax.set_title('Precisión en el Conjunto de Prueba para el Modelo Híbrido (Stacking)')\n\nfor i, v in enumerate([top1_accuracy * 100]):\n    ax.text(i, v + 1, f\"{v:.2f}%\", ha='center', va='bottom')\n\nfigure_filename = \"precision_prueba_hibrido.png\"\nsave_matplotlib_figure(fig, figure_filename)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEvaluación del Modelo Híbrido (Stacked Ensemble):\nModelMetricsMultinomialGLM: stackedensemble\n** Reported on test data. **\n\nMSE: 0.14121143756164278\nRMSE: 0.375781103252469\nLogLoss: 0.45535311703744163\nNull degrees of freedom: 599\nResidual degrees of freedom: 538\nNull deviance: 2495.3298500157935\nResidual deviance: 546.42374044493\nAUC table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\nAUCPR table was not computed: it is either disabled (model parameter 'auc_type' was set to AUTO or NONE) or the domain size exceeds the limit (maximum is 50 domains).\n\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\n0    1    2    3    4    5    6    7    Error      Rate\n---  ---  ---  ---  ---  ---  ---  ---  ---------  --------\n70   0    0    0    3    2    0    0    0.0666667  5 / 75\n0    51   0    0    13   1    0    10   0.32       24 / 75\n2    0    73   0    0    0    0    0    0.0266667  2 / 75\n1    0    0    69   4    1    0    0    0.08       6 / 75\n3    0    0    1    49   7    9    6    0.346667   26 / 75\n1    0    0    0    4    61   1    8    0.186667   14 / 75\n0    0    0    0    0    0    71   4    0.0533333  4 / 75\n0    0    0    0    2    6    8    59   0.213333   16 / 75\n77   51   73   70   75   78   89   87   0.161667   97 / 600\n\nTop-8 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.838333\n2    0.943333\n3    0.983333\n4    0.991667\n5    0.996667\n6    1\n7    1\n8    1\nTabla de Hit Ratios (Top-k Accuracy):\nTop-8 Hit Ratios: \nk    hit_ratio\n---  -----------\n1    0.838333\n2    0.943333\n3    0.983333\n4    0.991667\n5    0.996667\n6    1\n7    1\n8    1\nTop-1 Accuracy (equivalente a Precisión) del modelo híbrido (Stacking): 94.33%\nMatriz de Confusión del modelo híbrido (Stacking):\nConfusion Matrix: Row labels: Actual class; Column labels: Predicted class\n0    1    2    3    4    5    6    7    Error      Rate\n---  ---  ---  ---  ---  ---  ---  ---  ---------  --------\n70   0    0    0    3    2    0    0    0.0666667  5 / 75\n0    51   0    0    13   1    0    10   0.32       24 / 75\n2    0    73   0    0    0    0    0    0.0266667  2 / 75\n1    0    0    69   4    1    0    0    0.08       6 / 75\n3    0    0    1    49   7    9    6    0.346667   26 / 75\n1    0    0    0    4    61   1    8    0.186667   14 / 75\n0    0    0    0    0    0    71   4    0.0533333  4 / 75\n0    0    0    0    2    6    8    59   0.213333   16 / 75\n77   51   73   70   75   78   89   87   0.161667   97 / 600\nPrecisión (cálculo manual) del modelo híbrido (Stacking): 83.59%\n\nDataFrame de la matriz de confusión:\n       0     1     2     3     4     5     6     7     Error      Rate\n0  70.0   0.0   0.0   0.0   3.0   2.0   0.0   0.0  0.066667    5 / 75\n1   0.0  51.0   0.0   0.0  13.0   1.0   0.0  10.0  0.320000   24 / 75\n2   2.0   0.0  73.0   0.0   0.0   0.0   0.0   0.0  0.026667    2 / 75\n3   1.0   0.0   0.0  69.0   4.0   1.0   0.0   0.0  0.080000    6 / 75\n4   3.0   0.0   0.0   1.0  49.0   7.0   9.0   6.0  0.346667   26 / 75\n5   1.0   0.0   0.0   0.0   4.0  61.0   1.0   8.0  0.186667   14 / 75\n6   0.0   0.0   0.0   0.0   0.0   0.0  71.0   4.0  0.053333    4 / 75\n7   0.0   0.0   0.0   0.0   2.0   6.0   8.0  59.0  0.213333   16 / 75\n8  77.0  51.0  73.0  70.0  75.0  78.0  89.0  87.0  0.161667  97 / 600\nArchivo matriz_confusion_stacking_h2o_optimized.png ya existe. Se omite el guardado para acelerar la ejecución.\nArchivo precision_prueba_hibrido.png ya existe. Se omite el guardado para acelerar la ejecución.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](CPP3_Apaza_Cabezas_Ponce_Ruiz_files/figure-pdf/cell-27-output-2.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output .cell-output-display}\n![](CPP3_Apaza_Cabezas_Ponce_Ruiz_files/figure-pdf/cell-27-output-3.pdf){fig-pos='H'}\n:::\n:::\n\n\n\\figuragraficos{matriz_confusion_stacking_h2o_optimized.png}{Matriz de Confusion Stacking H2O}\n\\figuragraficos{precision_prueba_hibrido.png}{Precisión en el Conjunto de Prueba para el Modelo Híbrido}\n\n## Guardar y Cargar el Modelo Híbrido\n\nGuardamos el modelo de ensamble para su uso futuro y mostramos cómo cargarlo.\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\n# Guardar el modelo de Stacking\nensemble_path = h2o.save_model(model=ensemble, path=\".\", force=True)\nprint(f\"Modelo híbrido (Stacked Ensemble) guardado en: {ensemble_path}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModelo híbrido (Stacked Ensemble) guardado en: C:\\Users\\Jerson\\Downloads\\quarto\\CPP3_Apaza_Cabezas_Ponce_Ruiz\\ensemble_model\n```\n:::\n:::\n\n\nGuardar una representación gráfica del guardado del modelo híbrido utilizando Matplotlib\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\n# Crear una representación gráfica simple del guardado del modelo híbrido\nfig, ax = plt.subplots(figsize=(6,4))\nax.text(0.5, 0.5, f\"Modelo híbrido (Stacked Ensemble) guardado en:\\n{ensemble_path}\", \n        ha='center', va='center', fontsize=12, color='blue')\nax.axis('off')\nax.set_title('Guardado del Modelo Híbrido')\n\n# Guardar la figura\nsave_matplotlib_figure(fig, \"guardar_cargar_modelo_optimized.png\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nArchivo guardar_cargar_modelo_optimized.png ya existe. Se omite el guardado para acelerar la ejecución.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](CPP3_Apaza_Cabezas_Ponce_Ruiz_files/figure-pdf/cell-29-output-2.pdf){fig-pos='H'}\n:::\n:::\n\n\n\\figuragraficos{guardar_cargar_modelo_optimized.png}{Guardado y Carga del Modelo Híbrido Optimizado}\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\n# Cargar el modelo Híbrido\nloaded_ensemble = h2o.load_model(ensemble_path)\nprint(\"Modelo híbrido (Stacked Ensemble) cargado exitosamente.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModelo híbrido (Stacked Ensemble) cargado exitosamente.\n```\n:::\n:::\n\n\n# Comparación con el Modelo CNN\n\nComparamos el rendimiento del modelo híbrido con el modelo CNN entrenado previamente.\n\n**Resultados obtenidos:**\n\n-   **Precisión en el conjunto de prueba (CNN)**: Se alcanzó una precisión del `{{cnn_test_accuracy}}%`, lo cual indica que el modelo CNN es capaz de clasificar correctamente las enfermedades en un alto porcentaje de casos.\n    \n-   **Precisión del modelo híbrido (Stacking) con H2O**: El modelo híbrido basado en Stacking logró una precisión de `{{accuracy * 100:.2f}}%`, demostrando la efectividad de combinar múltiples modelos base para mejorar el desempeño.\n    \n-   **Distribución de clases balanceada**: La distribución uniforme de las clases en los conjuntos de entrenamiento, validación y prueba contribuyó a un aprendizaje efectivo del modelo sin sesgos.\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\n# Generar y guardar una representación gráfica de la comparación de precisión utilizando Matplotlib\ncomparacion_modelos = ['CNN', 'Híbrido']\n# Utiliza top1_accuracy para el modelo híbrido\nprecisiones = [cnn_test_accuracy, top1_accuracy * 100]\n\nfig, ax = plt.subplots(figsize=(8,6))\nbars = ax.bar(comparacion_modelos, precisiones, color=['lightsalmon', 'lightgreen'])\nax.set_ylim(0, 100)\nax.set_ylabel('Precisión (%)')\nax.set_title('Comparación de Precisión entre Modelos CNN y Híbrido')\n\n# Añadir etiquetas de precisión sobre las barras\nfor bar in bars:\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height + 1, \n            f'{height:.2f}%', ha='center', va='bottom')\n\n# Guardar la figura\nfigure_filename = \"comparacion_modelos_optimized.png\"\nsave_matplotlib_figure(fig, figure_filename)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nArchivo comparacion_modelos_optimized.png ya existe. Se omite el guardado para acelerar la ejecución.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](CPP3_Apaza_Cabezas_Ponce_Ruiz_files/figure-pdf/cell-31-output-2.pdf){fig-pos='H'}\n:::\n:::\n\n\n\\figuragraficos{comparacion_modelos_optimized.png}{Comparación de Precisión entre Modelos CNN y Híbrido Optimizado}\n\n# Conclusiones\n\nEn este proyecto, hemos desarrollado un **Modelo Híbrido** para la clasificación de enfermedades en hojas de mango utilizando técnicas avanzadas de **Ensemble Learning** con **H2O**. El proceso incluyó:\n\n-   **Preparación y Análisis de Datos**: Organización de imágenes, etiquetado y división en conjuntos de entrenamiento, validación y prueba.\n    \n-   **Modelo CNN con PyTorch**: Implementación y entrenamiento de una red neuronal convolucional para la extracción de características de las imágenes.\n    \n-   **Modelo Base con H2O Random Forest**: Entrenamiento de un modelo Random Forest optimizado para GPU con una búsqueda de hiperparámetros simplificada utilizando `H2OGridSearch`.\n    \n-   **Modelo Híbrido con Stacking**: Creación de un ensamble apilado utilizando el modelo base optimizado para mejorar el rendimiento de la clasificación.\n    \n-   **Evaluación y Visualización**: Evaluación de los modelos utilizando métricas como precisión, recall y F1-score, y visualización de los resultados mediante matrices de confusión y reportes de clasificación.\n    \n-   **Guardado y Carga de Modelos**: Persistencia de los modelos entrenados para su uso futuro.\n\n**Resultados obtenidos:**\n\n-   **Precisión en el conjunto de prueba (CNN)**: Se alcanzó una precisión del `{{cnn_test_accuracy}}%`, lo cual indica que el modelo CNN es capaz de clasificar correctamente las enfermedades en un alto porcentaje de casos.\n    \n-   **Precisión del modelo híbrido (Stacking) con H2O**: El modelo híbrido basado en Stacking logró una precisión de `{{accuracy * 100:.2f}}%`, demostrando la efectividad de combinar múltiples modelos base para mejorar el desempeño.\n    \n-   **Distribución de clases balanceada**: La distribución uniforme de las clases en los conjuntos de entrenamiento, validación y prueba contribuyó a un aprendizaje efectivo del modelo sin sesgos.\n\n**Mejoras futuras:**\n\n-   **Aumento de Datos**: Implementar técnicas más avanzadas de data augmentation para mejorar la robustez y generalización del modelo.\n    \n-   **Arquitecturas Más Profundas**: Experimentar con arquitecturas de redes neuronales más complejas, como **ResNet** o **EfficientNet**, utilizando las capacidades de Deep Learning de H2O para potencialmente mejorar la precisión.\n    \n-   **Optimización Avanzada**: Utilizar optimizadores y técnicas de regularización más avanzadas, como aprendizaje por transferencia, para mejorar aún más el rendimiento.\n    \n-   **Evaluación con Más Métricas**: Incluir métricas adicionales como **AUC-ROC** para una evaluación más completa del desempeño del modelo.\n\nEste enfoque híbrido, combinando el poder de las redes neuronales convolucionales con la flexibilidad de los modelos de ensamble de H2O, proporciona una solución robusta y eficiente para la clasificación de enfermedades en hojas de mango.\n\n# Referencias\n\n-   He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. En *Proceedings of the IEEE conference on computer vision and pattern recognition* (pp. 770-778).\n    \n-   Brownlee, J. (2019). *Deep Learning for Computer Vision*. Machine Learning Mastery.\n    \n-   Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.\n\n",
    "supporting": [
      "CPP3_Apaza_Cabezas_Ponce_Ruiz_files"
    ],
    "filters": []
  }
}